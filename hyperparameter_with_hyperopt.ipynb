{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAJcIFn7coYSyeEPtI/FFA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow hyperopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQKzwYSXtsVJ",
        "outputId": "64eb1ca9-dd0b-4907-822a-717aeecfcee7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.9.2-py3-none-any.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.0.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.23)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<15,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (10.0.1)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.5.1)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.0.7)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow) (1.7.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, querystring-parser, Mako, gunicorn, gitdb, docker, databricks-cli, alembic, gitpython, mlflow\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.1 databricks-cli-0.18.0 docker-6.1.3 gitdb-4.0.11 gitpython-3.1.40 gunicorn-21.2.0 mlflow-2.9.2 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utils function"
      ],
      "metadata": {
        "id": "xQkGOGf7ugfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# buat dummy dataset untuk testing\n",
        "def create_dataset(\n",
        "    n_samples: int = 10000,\n",
        "    n_features: int = 50,\n",
        "    n_informative: int = 10,\n",
        "    class_sep: float = 1.0,\n",
        ") -> pd.DataFrame:\n",
        "\n",
        "    x, y = make_classification(\n",
        "        n_samples=n_samples,\n",
        "        n_features=n_features,\n",
        "        n_informative=n_informative,\n",
        "        class_sep=class_sep,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    df = pd.DataFrame(x, columns=[f\"feature_{i}\" for i in range(n_features)])\n",
        "    df[\"target\"] = y\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "9_zq_yVktjWN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from typing import Any\n",
        "# buat eksperimen di mlflow\n",
        "def create_mlflow_experiment(\n",
        "    experiment_name: str, artifact_location: str, tags: dict[str, Any]\n",
        ") -> str:\n",
        "    try:\n",
        "        experiment_id = mlflow.create_experiment(\n",
        "            name=experiment_name, artifact_location=artifact_location, tags=tags\n",
        "        )\n",
        "    except:\n",
        "        print(f\"Experiment {experiment_name} already exists.\")\n",
        "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
        "\n",
        "    mlflow.set_experiment(experiment_name=experiment_name)\n",
        "\n",
        "    return experiment_id"
      ],
      "metadata": {
        "id": "x8364eGVumBq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dummy hyperparameter tuning basic\n",
        "kasusnya mencari hyperparameter pd kasus rumus $(x+3)^2 + 2$"
      ],
      "metadata": {
        "id": "D2tjp20tunqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# untuk mendptkan nilai minimum (yg diinginkan)\n",
        "from hyperopt import fmin, tpe, Trials, hp\n",
        "\n",
        "# kasusnya mencari hyperparameter pd kasus rumus (x+3)^2 + 2\n",
        "def objective_function(params):\n",
        "  y = (params['x'] + 3) ** 2 + 2\n",
        "  return y\n",
        "\n",
        "# hyperparameter nya bernilai -10 sampai 10 dg distribusi uniform\n",
        "search_space = {\n",
        "    'x': hp.uniform('x', -10, 10)\n",
        "}\n",
        "\n",
        "trials = Trials()\n",
        "\n",
        "# mencari hyperparameter terbaik (menemukan nilai x yg paling minimum)\n",
        "best = fmin(\n",
        "  fn = objective_function,\n",
        "  space = search_space,\n",
        "  algo = tpe.suggest,\n",
        "  max_evals = 100,\n",
        "  trials = trials\n",
        ")\n",
        "\n",
        "print(best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czIR3vBIuraK",
        "outputId": "2151ef3e-3bbf-4dff-88e0-4ff1489bc302"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 194.10trial/s, best loss: 2.0000349536313244]\n",
            "{'x': -3.005912159615937}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# hyperparameter tuning with model"
      ],
      "metadata": {
        "id": "BBGxyZcHwX-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sD1KP_SdiDXR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f7a3d6-6aba-4860-9a35-35fcd3e0ed2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49']\n",
            " 10%|█         | 1/10 [00:07<01:04,  7.11s/trial, best loss: -0.8808184143222506]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 10/10 [01:38<00:00,  9.89s/trial, best loss: -0.9058882737795673]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from hyperopt import fmin\n",
        "from hyperopt import tpe\n",
        "from hyperopt import Trials\n",
        "from hyperopt import hp\n",
        "\n",
        "from typing import Dict\n",
        "from typing import List\n",
        "from typing import Optional\n",
        "\n",
        "import pandas as pd\n",
        "import mlflow\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "def get_classification_metrics(y_true: pd.Series, y_pred: pd.Series, prefix: str) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Get the classification metrics.\n",
        "\n",
        "    :param y_true: The true target values.\n",
        "    :param y_pred: The predicted target values.\n",
        "    :param prefix: The prefix of the metric names.\n",
        "    :return: The classification metrics.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        f\"{prefix}_accuracy\": accuracy_score(y_true=y_true, y_pred=y_pred),\n",
        "        f\"{prefix}_precision\": precision_score(y_true=y_true, y_pred=y_pred),\n",
        "        f\"{prefix}_recall\": recall_score(y_true=y_true, y_pred=y_pred),\n",
        "        f\"{prefix}_f1\": f1_score(y_true=y_true, y_pred=y_pred),\n",
        "    }\n",
        "\n",
        "\n",
        "def get_sklearn_pipeline(numerical_features: List[str], categorical_features: Optional[List[str]] = []) -> Pipeline:\n",
        "    \"\"\"\n",
        "    Get the sklearn pipeline.\n",
        "    :param numerical_features: The numerical features.\n",
        "    :param categorical_features: The categorical features.\n",
        "    :return: The sklearn pipeline.\n",
        "    \"\"\"\n",
        "    preprocessing = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"numerical\", SimpleImputer(strategy=\"median\"), numerical_features),\n",
        "            (\n",
        "                \"categorical\",\n",
        "                OneHotEncoder(),\n",
        "                categorical_features,\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    pipeline = Pipeline(\n",
        "        steps=[\n",
        "            (\"preprocessing\", preprocessing),\n",
        "            (\"model\", RandomForestClassifier()),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return pipeline\n",
        "\n",
        "def objective_function(\n",
        "    params: Dict,\n",
        "    x_train: pd.DataFrame,\n",
        "    x_test: pd.DataFrame,\n",
        "    y_train: pd.DataFrame,\n",
        "    y_test: pd.DataFrame,\n",
        "    numerical_features: List[str],\n",
        "    categorical_features: List[str],\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Objective function to minimize.\n",
        "\n",
        "    :param params: The hyperparameter values to evaluate.\n",
        "    :param x_train: The training data.\n",
        "    :param x_test: The test data.\n",
        "    :param y_train: The training target.\n",
        "    :param y_test: The test target.\n",
        "    :param numerical_features: The numerical features.\n",
        "    :param categorical_features: The categorical features.\n",
        "    :return: The score of the model.\n",
        "    \"\"\"\n",
        "    pipeline = get_sklearn_pipeline(numerical_features=numerical_features)\n",
        "    params.update({\"model__max_depth\": int(params[\"model__max_depth\"])})\n",
        "    params.update({\"model__n_estimators\": int(params[\"model__n_estimators\"])})\n",
        "    pipeline.set_params(**params)\n",
        "    with mlflow.start_run(nested=True) as run:\n",
        "        pipeline.fit(x_train, y_train)\n",
        "        y_pred = pipeline.predict(x_test)\n",
        "        metrics = get_classification_metrics(\n",
        "            y_true=y_test, y_pred=y_pred, prefix=\"test\"\n",
        "        )\n",
        "\n",
        "        mlflow.log_params(pipeline[\"model\"].get_params())\n",
        "        mlflow.log_metrics(metrics)\n",
        "        mlflow.sklearn.log_model(pipeline, f\"{run.info.run_id}-model\")\n",
        "    return -metrics[\"test_f1\"]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = create_dataset()\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        df.drop(\"target\", axis=1),\n",
        "        df[\"target\"],\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    numerical_features = [f for f in x_train.columns if f.startswith(\"feature\")]\n",
        "    print(numerical_features)\n",
        "\n",
        "    space = {\n",
        "        \"model__n_estimators\": hp.quniform(\"model__n_estimators\", 20, 200, 10),\n",
        "        \"model__max_depth\": hp.quniform(\"model__max_depth\", 10, 100, 10),\n",
        "    }\n",
        "\n",
        "    experiment_id = create_mlflow_experiment(\n",
        "        \"hyperopt_experiment\",\n",
        "        artifact_location=\"hyperopt_mlflow_artifacts\",\n",
        "        tags={\"mlflow.note.content\": \"hyperopt experiment\"},\n",
        "    )\n",
        "    with mlflow.start_run(run_name=\"hyperparameter_opmization\") as run:\n",
        "        best_params = fmin(\n",
        "            fn=partial(\n",
        "                objective_function,\n",
        "                x_train=x_train,\n",
        "                x_test=x_test,\n",
        "                y_train=y_train,\n",
        "                y_test=y_test,\n",
        "                numerical_features=numerical_features,\n",
        "                categorical_features=None,\n",
        "            ),\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=10,\n",
        "            trials=Trials(),\n",
        "        )\n",
        "\n",
        "        pipeline = get_sklearn_pipeline(numerical_features=numerical_features)\n",
        "\n",
        "        best_params.update({\"model__max_depth\": int(best_params[\"model__max_depth\"])})\n",
        "        best_params.update(\n",
        "            {\"model__n_estimators\": int(best_params[\"model__n_estimators\"])}\n",
        "        )\n",
        "\n",
        "        pipeline.set_params(**best_params)\n",
        "        pipeline.fit(x_train, y_train)\n",
        "        y_pred = pipeline.predict(x_test)\n",
        "        metrics = get_classification_metrics(\n",
        "            y_true=y_test, y_pred=y_pred, prefix=\"best_model_test\"\n",
        "        )\n",
        "\n",
        "        mlflow.log_params(pipeline[\"model\"].get_params())\n",
        "        mlflow.log_metrics(metrics)\n",
        "        mlflow.sklearn.log_model(pipeline, f\"{run.info.run_id}-best-model\")"
      ]
    }
  ]
}